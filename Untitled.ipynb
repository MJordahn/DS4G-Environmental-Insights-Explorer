{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import rasterio as rio\n",
    "import folium\n",
    "import cv2 as cv\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from torchvision.datasets import ImageFolder\n",
    "\n",
    "#from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NO2Dataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_files_list = [s for s in os.listdir(root_dir)]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "        \n",
    "        # path to image\n",
    "        path_to_image = os.path.join(self.root_dir, self.image_files_list[index])\n",
    "        \n",
    "        # get image and image band\n",
    "        image= rio.open(path_to_image)\n",
    "        band = self.transform(image.read(2))\n",
    "        \n",
    "        return band, image.name\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './eie_data/cleaned_s5p_no2/container/'\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()]\n",
    ")\n",
    "# Dataset\n",
    "data = NO2Dataset(path, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag = 4\n",
    "batch_size = 2\n",
    "\n",
    "# Data laoder\n",
    "train_loader = DataLoader(dataset=data, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 148, 475])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(dataiter)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
