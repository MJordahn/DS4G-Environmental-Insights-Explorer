{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import rasterio as rio\n",
    "import folium\n",
    "import cv2 as cv\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_dict = {}\n",
    "for file in os.listdir('./eie_data/cleaned_gfs/'):\n",
    "    weather_dict[file.split(\"_\")[2].replace(\"XX.tif\", \"\")[0:8]] = file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/feature_extraction/image.py:287: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  indexing_strides = arr[slices].strides\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def plot_scaled(file_name):\n",
    "    vmin, vmax = np.nanpercentile(file_name, (5,95))  # 5-95% stretch\n",
    "    img_plt = plt.imshow(file_name, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    plt.show()\n",
    "\n",
    "def increment_name(day, month, year):\n",
    "    day += 1\n",
    "    if day > 31:\n",
    "        day = 1\n",
    "        month += 1\n",
    "        if month > 12:\n",
    "            month = 1\n",
    "            year += 1\n",
    "    return day, month, year\n",
    "    \n",
    "\n",
    "patch_size = (3,3)\n",
    "dir_list = os.listdir('./eie_data/cleaned_s5p_no2/')\n",
    "dir_gfs_list = os.listdir('./eie_data/cleaned_gfs/')\n",
    "dir_list = sorted(dir_list)\n",
    "path = './eie_data/cleaned_s5p_no2/'\n",
    "length = len(dir_list)\n",
    "first_run = True\n",
    "im_to_include = 10\n",
    "for i, file in enumerate(dir_list):\n",
    "    if i != length-1:\n",
    "        image_feature = rio.open(path+file)\n",
    "        shape_feature = image_feature.read(2)\n",
    "        NO2_patch_feature = image.extract_patches_2d(shape_feature, patch_size)\n",
    "        NO2_patch_feature = np.array([i.reshape(patch_size[0]*patch_size[1]) for i in NO2_patch_feature])\n",
    "        week_features = NO2_patch_feature\n",
    "        image_label = rio.open(path+dir_list[i+1])\n",
    "        shape_label = image_label.read(2)\n",
    "        NO2_patch_label = image.extract_patches_2d(shape_label, patch_size)\n",
    "        NO2_patch_label = np.array([i.reshape(patch_size[0]*patch_size[1]) for i in NO2_patch_label])\n",
    "        if first_run == True:\n",
    "            labels = NO2_patch_label\n",
    "        else:\n",
    "            labels = np.append(labels, NO2_patch_label, axis=0)\n",
    "        split_file_name = file.split(\"_\")\n",
    "        begin_period = split_file_name[3][0:8]\n",
    "        end_period = split_file_name[4].replace(\".tif\", \"\")[0:8]\n",
    "        day = int(begin_period[-2:])\n",
    "        month = int(begin_period[-4:-2])\n",
    "        year = int(begin_period[0:-4])\n",
    "        date = datetime(year,month,day)\n",
    "        for j in range(0,7):\n",
    "            year_str = str(date.year)\n",
    "            month_str = str(date.month)\n",
    "            day_str = str(date.day)\n",
    "            if len(month_str) < 2:\n",
    "                month_str = \"0\" + month_str\n",
    "            if len(day_str) < 2:\n",
    "                day_str = \"0\" + day_str\n",
    "            filename = year_str+month_str+day_str\n",
    "            date += timedelta(days=1)\n",
    "            path_gfs = './eie_data/cleaned_gfs/'+weather_dict[filename]\n",
    "            image_feature = rio.open(path_gfs)\n",
    "            for q in range (1, 7):\n",
    "                weather_patch_feature = image.extract_patches_2d(image_feature.read(q), patch_size)\n",
    "                weather_patch_feature = np.array([i.reshape(patch_size[0]*patch_size[1]) for i in weather_patch_feature])\n",
    "                week_features = np.concatenate((week_features, weather_patch_feature), axis=1)\n",
    "        if first_run == True:\n",
    "            features = week_features\n",
    "        else:\n",
    "            features = np.concatenate((features, week_features), axis=0)\n",
    "    if file == \"cleaned_s5p_no2_20190623T161923_20190629T180700.tif\":\n",
    "        break\n",
    "    first_run = False\n",
    "    if i > im_to_include-2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(138116, 9)\n",
      "(138116,)\n",
      "(138116, 387)\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)\n",
    "labels = np.array([label[int((patch_size[0]*patch_size[1]/2))] for label in labels])\n",
    "print(labels.shape)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.06017138e-08\n",
      " -0.00000000e+00 -0.00000000e+00 -1.98114299e-08 -9.33432679e-08\n",
      " -8.61758753e-10 -1.29954434e-07  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.10446745e-07 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -1.09710564e-08 -2.04671467e-09 -1.12921865e-07 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -4.07235585e-08 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -1.02859167e-07 -0.00000000e+00\n",
      " -8.48200657e-08 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "labels = pd.read_csv(\"labels.csv\").drop([\"Unnamed: 0\"], axis=1)\n",
    "features = pd.read_csv(\"features_images.csv\").drop([\"Unnamed: 0\"], axis=1)\n",
    "clf = Lasso(alpha=0.0000005)\n",
    "clf.fit(features, labels)\n",
    "print(clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd \n",
    "#pd.DataFrame(features).to_csv(\"features_images.csv\")\n",
    "#pd.DataFrame(labels).to_csv(\"labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import image\n",
    "patch_size = (3,3)\n",
    "dir_list = os.listdir('./eie_data/cleaned_s5p_no2/')\n",
    "dir_gfs_list = os.listdir('./eie_data/cleaned_gfs/')\n",
    "dir_list = sorted(dir_list)\n",
    "path = './eie_data/cleaned_s5p_no2/'\n",
    "length = len(dir_list)\n",
    "first_run = True\n",
    "\n",
    "for i, file in enumerate(dir_list):\n",
    "    if i != length-1 and i >10:\n",
    "        image_feature = rio.open(path+file)\n",
    "        shape_feature = image_feature.read(2)\n",
    "        NO2_patch_feature = image.extract_patches_2d(shape_feature, patch_size)\n",
    "        NO2_patch_feature = np.array([i.reshape(patch_size[0]*patch_size[1]) for i in NO2_patch_feature])\n",
    "        week_features = NO2_patch_feature\n",
    "        image_label = rio.open(path+dir_list[i+1])\n",
    "        shape_label = image_label.read(2)\n",
    "        NO2_patch_label = image.extract_patches_2d(shape_label, patch_size)\n",
    "        NO2_patch_label = np.array([i.reshape(patch_size[0]*patch_size[1]) for i in NO2_patch_label])\n",
    "        if first_run == True:\n",
    "            labels = NO2_patch_label\n",
    "        else:\n",
    "            labels = np.append(features, NO2_patch_label, axis=0)\n",
    "        split_file_name = file.split(\"_\")\n",
    "        begin_period = split_file_name[3][0:8]\n",
    "        end_period = split_file_name[4].replace(\".tif\", \"\")[0:8]\n",
    "        day = int(begin_period[-2:])\n",
    "        month = int(begin_period[-4:-2])\n",
    "        year = int(begin_period[0:-4])\n",
    "        date = datetime(year,month,day)\n",
    "        for j in range(0,7):\n",
    "            year_str = str(date.year)\n",
    "            month_str = str(date.month)\n",
    "            day_str = str(date.day)\n",
    "            if len(month_str) < 2:\n",
    "                month_str = \"0\" + month_str\n",
    "            if len(day_str) < 2:\n",
    "                day_str = \"0\" + day_str\n",
    "            filename = year_str+month_str+day_str\n",
    "            date += timedelta(days=1)\n",
    "            path_gfs = './eie_data/cleaned_gfs/'+weather_dict[filename]\n",
    "            image_feature = rio.open(path_gfs)\n",
    "            for q in range (1, 7):\n",
    "                weather_patch_feature = image.extract_patches_2d(image_feature.read(q), patch_size)\n",
    "                weather_patch_feature = np.array([i.reshape(patch_size[0]*patch_size[1]) for i in weather_patch_feature])\n",
    "                week_features = np.concatenate((week_features, weather_patch_feature), axis=1)\n",
    "        if first_run == True:\n",
    "            features = week_features\n",
    "        else:\n",
    "            features = np.concatenate(features, week_features, axis=0)\n",
    "        first_run = False\n",
    "    if file == \"cleaned_s5p_no2_20190623T161923_20190629T180700.tif\":\n",
    "        break\n",
    "   \n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.65502211e-06]\n",
      "[2.10253351e-06 2.10253351e-06 2.10253351e-06 ... 3.06908358e-07\n",
      " 3.06908358e-07 3.06908358e-07]\n",
      "-0.5219173714461678\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(features)\n",
    "#print(features[0].reshape(-1,1))\n",
    "print(clf.predict(features[10000].reshape(1,-1)))\n",
    "#labels = np.array([label[int((patch_size[0]*patch_size[1]/2))] for label in labels])\n",
    "print(predictions)\n",
    "#print(labels)\n",
    "print(np.sum(predictions-labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
